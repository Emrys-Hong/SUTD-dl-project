{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import apex\n",
    "import data\n",
    "import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reports: 3851\n",
      "Skipped: 3648 images\n",
      "Sample:\n",
      "* Image size: torch.Size([3, 2048, 2048])\n",
      "* Impression: tensor([37, 38, 41, 36, 24, 35,  0, 26, 31, 28, 42, 43,  0, 47,  6, 47, 47, 47,\n",
      "        47,  7])\n",
      "* Vocab:\n",
      "['2', 'y', \"'\", '>', '-', 'm', 'e', 'v', 'o', 'b', 'u', '1', '6', 'a', 'c', '0', '3', 'k', '8', 'z', ':', 'r', '5', 'd', '.', '%', '<', '9', '(', 'i', 't', 'f', 'p', 'w', '\"', 'q', ')', ' ', 'n', '7', '/', 'h', 's', 'x', ';', 'j', '[', 'g', 'l', '4']\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_dataset = data.XRayDataset(\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(2048),\n",
    "        transforms.CenterCrop((2048,2048)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25]),\n",
    "        ]\n",
    "))\n",
    "\n",
    "print(\"Sample:\")\n",
    "image, impression = train_dataset.__getitem__(0)\n",
    "print(\"* Image size:\", image.size())\n",
    "print(\"* Impression:\", impression)\n",
    "print(\"* Vocab:\")\n",
    "print(train_dataset.vocab)\n",
    "\n",
    "train_dataloader = torch.utils.data.dataloader.DataLoader(train_dataset,\n",
    "                                                          collate_fn=data.collate_fn,\n",
    "                                                          pin_memory=True,\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          num_workers=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "embed_size = 128\n",
    "hidden_size = 128\n",
    "num_layers = 3\n",
    "learning_rate = 0.001\n",
    "memory_format = torch.channels_last\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder = models.EncoderCNN(embed_size).to(device, memory_format=memory_format)\n",
    "decoder = models.DecoderRNN(embed_size, hidden_size, len(train_dataset.vocab), num_layers).to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "params = list(decoder.parameters()) + list(encoder.parameters())\n",
    "optimizer = apex.optimizers.FusedAdam(params, lr=learning_rate)\n",
    "\n",
    "[encoder, decoder], optimizer = apex.amp.initialize([encoder, decoder], optimizer, opt_level=\"O1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch [0/3], Step [0/3484], Loss: 3.9329, Perplexity: 51.0573\n",
      "Epoch [0/3], Step [100/3484], Loss: 2.9804, Perplexity: 19.6951\n",
      "Epoch [0/3], Step [200/3484], Loss: 2.7066, Perplexity: 14.9776\n",
      "Epoch [0/3], Step [300/3484], Loss: 2.3290, Perplexity: 10.2675\n",
      "Epoch [0/3], Step [400/3484], Loss: 2.1858, Perplexity: 8.8977\n",
      "Epoch [1/3], Step [0/3484], Loss: 1.6587, Perplexity: 5.2522\n",
      "Epoch [1/3], Step [100/3484], Loss: 1.1066, Perplexity: 3.0240\n",
      "Epoch [1/3], Step [200/3484], Loss: 0.9805, Perplexity: 2.6659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 294, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 487, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 614, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-be282afce6e4>\", line 8, in <module>\n",
      "    for i, (images, captions, lengths) in enumerate(train_dataloader):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 345, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 841, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 798, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 761, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.6/queue.py\", line 173, in get\n",
      "    self.not_empty.wait(remaining)\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 299, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/opt/conda/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/opt/conda/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/opt/conda/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "total_step = len(train_dataloader.dataset)\n",
    "\n",
    "print(\"Start training\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, captions, lengths) in enumerate(train_dataloader):\n",
    "\n",
    "        # Set mini-batch dataset\n",
    "        images = images.cuda(non_blocking=True).contiguous(memory_format=memory_format)\n",
    "        captions = captions.cuda(non_blocking=True).contiguous()\n",
    "        targets = torch.nn.utils.rnn.pack_padded_sequence(captions, lengths, batch_first=True)[0]\n",
    "        \n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "\n",
    "        # Forward, backward and optimize\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions, lengths)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        with apex.amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print log info\n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Perplexity: {:5.4f}\"\n",
    "                  .format(epoch, num_epochs, i, total_step, loss.item(), np.exp(loss.item()))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
