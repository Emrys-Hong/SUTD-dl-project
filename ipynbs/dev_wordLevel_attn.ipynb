{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.chdir('..')\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import apex\n",
    "import csv\n",
    "import dataset_word as data\n",
    "import models_attn as models\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tqdm.notebook import tqdm\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "#from config import config\n",
    "\n",
    "class Config:\n",
    "    # data\n",
    "    cleaned_reports = \"./xray-dataset/cleaned_reports.csv\"\n",
    "    image_dir = \"./xray-dataset/images/images_normalized/\"\n",
    "    file_list = \"./xray-dataset/indiana_projections.csv\"\n",
    "    pretrained_emb = True    \n",
    "    emb_file = \"./vectors/glove.6B.300d.txt\"\n",
    "    PAD_idx = 0\n",
    "    UNK_idx = 1\n",
    "    EOS_idx = 2\n",
    "    SOS_idx = 3\n",
    "\n",
    "    # model\n",
    "    emb_dim = 300\n",
    "    hidden_dim = 256\n",
    "    num_layers = 3\n",
    "\n",
    "    # training\n",
    "    batch_size = 32\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    # Others\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_list(input_str):    \n",
    "    return ast.literal_eval(input_str)\n",
    "\n",
    "reports = {}\n",
    "\n",
    "with open(config.cleaned_reports) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "        else:\n",
    "            uid, problems, findings, impression = row[1:]\n",
    "            reports[str(uid)] = (parse_list(problems), findings, impression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_report_splits(reports, seed=1337):\n",
    "    uid_list = list(reports.keys())\n",
    "    train_uids, valtest_uids = train_test_split(uid_list, test_size=0.2, random_state=seed)\n",
    "    valid_uids, test_uids = train_test_split(valtest_uids, test_size=0.5, random_state=seed)\n",
    "    \n",
    "    train_reports = {}\n",
    "    valid_reports = {}\n",
    "    test_reports = {}\n",
    "    splits = [train_uids, valid_uids, test_uids]\n",
    "    output_reports = [train_reports, valid_reports, test_reports]\n",
    "    \n",
    "    for i in range(len(splits)):\n",
    "        for uid in splits[i]:\n",
    "            output_reports[i][str(uid)] = reports[str(uid)]\n",
    "            \n",
    "    return output_reports\n",
    "\n",
    "train_reports, valid_reports, _ = create_report_splits(reports)\n",
    "\n",
    "train_dataset = data.XRayDataset(\n",
    "    reports=train_reports,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(299),\n",
    "        transforms.CenterCrop((299,299)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    "))\n",
    "train_dataloader = torch.utils.data.dataloader.DataLoader(train_dataset,\n",
    "                                                          collate_fn=data.collate_fn,\n",
    "                                                          pin_memory=True,\n",
    "                                                          shuffle=True,\n",
    "                                                          drop_last=True,\n",
    "                                                          batch_size=config.batch_size,\n",
    "                                                          num_workers=config.batch_size)\n",
    "\n",
    "valid_dataset = data.XRayDataset(\n",
    "    reports=valid_reports,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(299),\n",
    "        transforms.CenterCrop((299,299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "))\n",
    "valid_dataloader = torch.utils.data.dataloader.DataLoader(valid_dataset,\n",
    "                                                          collate_fn=data.collate_fn,\n",
    "                                                          pin_memory=True,\n",
    "                                                          shuffle=True,\n",
    "                                                          drop_last=True,\n",
    "                                                          batch_size=config.batch_size,\n",
    "                                                          num_workers=config.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "memory_format = torch.channels_last\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "encoder = models.EncoderCNN(config.emb_dim, num_classes).to(config.device, memory_format=memory_format)\n",
    "decoder = models.AttnDecoderRNN(attention_dim=config.hidden_dim*2,\n",
    "                                embed_dim=config.emb_dim,\n",
    "                                decoder_dim=config.hidden_dim,\n",
    "                                vocab_size=train_dataset.tokenizer.n_words,\n",
    "                                encoder_dim=512,\n",
    "                                device=config.device).to(config.device, memory_format=memory_format)\n",
    "\n",
    "classes_loss = torch.nn.BCEWithLogitsLoss()\n",
    "outputs_loss = torch.nn.CrossEntropyLoss()\n",
    "params = list(decoder.parameters()) + list(encoder.parameters())\n",
    "optimizer = apex.optimizers.FusedAdam(params, lr=config.learning_rate)\n",
    "\n",
    "[encoder, decoder], optimizer = apex.amp.initialize([encoder, decoder], optimizer, opt_level=\"O1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloader, batch_size, encoder, decoder, classes_loss, outputs_loss, optimizer, train=True):\n",
    "    total_step = len(dataloader.dataset)//batch_size\n",
    "    if train:\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "    else:\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "    running_c_loss = torch.Tensor([0.0])\n",
    "    running_o_loss = torch.Tensor([0.0])\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for i, (images, class_labels, captions, lengths) in enumerate(progress_bar(dataloader)):\n",
    "            images = images.to(config.device, non_blocking=True).contiguous(memory_format=memory_format)\n",
    "            captions = captions.to(config.device, non_blocking=True)\n",
    "            class_labels = class_labels.to(config.device, non_blocking=True)\n",
    "            encoder.zero_grad()\n",
    "            decoder.zero_grad()\n",
    "            logits, features = encoder(images)\n",
    "            c_loss = classes_loss(logits, class_labels)\n",
    "            \n",
    "            scores, caps_sorted, decode_lengths, alphas = decoder(features, captions, lengths)\n",
    "            scores = torch.nn.utils.rnn.pack_padded_sequence(scores, decode_lengths, batch_first=True, enforce_sorted=False)[0]\n",
    "            targets = captions[:, 1:]\n",
    "            targets = torch.nn.utils.rnn.pack_padded_sequence(targets, decode_lengths, batch_first=True, enforce_sorted=False)[0]\n",
    "            \n",
    "            o_loss = outputs_loss(scores, targets)\n",
    "            if train:\n",
    "                with apex.amp.scale_loss(c_loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward(retain_graph=True)\n",
    "                with apex.amp.scale_loss(o_loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                optimizer.step()\n",
    "            running_c_loss += c_loss\n",
    "            running_o_loss += o_loss\n",
    "    c_loss = float(running_c_loss.item()/total_step)\n",
    "    o_loss = float(running_o_loss.item()/total_step)\n",
    "    return c_loss, o_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "\n",
      "Epoch 1 / 3 :\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='84' class='' max='84', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [84/84 00:32<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='10' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [10/10 00:05<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -  0.16 5.543 - perplexity - 255.458 - valid_loss -  0.134 7.014 - perplexity - 1112.144\n",
      "\n",
      "Epoch 2 / 3 :\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='84' class='' max='84', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [84/84 00:30<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='10' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [10/10 00:05<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss -  0.144 4.899 - perplexity - 134.18 - valid_loss -  0.14 7.197 - perplexity - 1335.729\n",
      "\n",
      "Epoch 3 / 3 :\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='84' class='' max='84', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [84/84 00:32<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "print(\"Start training\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"\\nEpoch\", epoch+1, \"/\", num_epochs, \":\\n\")\n",
    "    \n",
    "    train_c_loss, train_o_loss = train_one_epoch(train_dataloader, config.batch_size, encoder, decoder, classes_loss, outputs_loss, optimizer, train=True)\n",
    "    valid_c_loss, valid_o_loss = train_one_epoch(valid_dataloader, config.batch_size, encoder, decoder, classes_loss, outputs_loss, optimizer, train=False)\n",
    "\n",
    "    print(\"train_loss - \", round(train_c_loss,3),round(train_o_loss,3), \"- perplexity -\", round(np.exp(train_o_loss),3), \n",
    "          \"- valid_loss - \", round(valid_c_loss,3),round(valid_o_loss,3), \"- perplexity -\", round(np.exp(valid_o_loss),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), 'save/encoder_word.pt')\n",
    "torch.save(decoder.state_dict(), 'save/decoder_word.pt')\n",
    "encoder.load_state_dict(torch.load('save/encoder_word.pt'))\n",
    "decoder.load_state_dict(torch.load('save/decoder_word.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(0, 1):\n",
    "    image, _, impression = train_dataset.__getitem__(index)\n",
    "    image_tensor = image.unsqueeze(0).to(config.device)\n",
    "    logits, features = encoder(image_tensor)\n",
    "    \n",
    "    seed = [\"SOS\", ]\n",
    "    seed = torch.from_numpy(train_dataset.tokenizer.encode(seed)).unsqueeze(0).cuda()\n",
    "    \n",
    "    predictions, seed, decode_lengths, alphas = decoder.sample(features, seed, [32, ])\n",
    "    alphas = alphas.reshape([1, 31, 64, 64])\n",
    "    alphas = torch.sum(alphas, 1).squeeze(0)\n",
    "    alphas = cv2.resize(alphas.detach().cpu().numpy(), (2048,2048))\n",
    "    alphas = np.clip(alphas, 0.0, 1.0)\n",
    "    \n",
    "    sampled_ids = list(predictions[0].cpu().numpy())\n",
    "\n",
    "    plt.title(\"Image: \"+str(index))\n",
    "    plt_img = np.moveaxis(image.numpy(), 0, -1)\n",
    "    plt.imshow(plt_img)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title(\"Image: \"+str(index))\n",
    "    plt.imshow(alphas)\n",
    "    plt.show()\n",
    "\n",
    "    print(\" Original:\", train_dataset.tokenizer.decode(impression))\n",
    "    print(\"Generated:\", train_dataset.tokenizer.decode(sampled_ids))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
